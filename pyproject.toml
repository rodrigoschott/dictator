[tool.poetry]
name = "dictator"
version = "0.1.0"
description = "Voice to Text - Local Whisper transcription with GPU support"
authors = ["Your Name <you@example.com>"]
readme = "README.md"
packages = [{include = "dictator", from = "src"}]

[tool.poetry.dependencies]
python = ">=3.10,<3.14"
faster-whisper = "^1.2.0"
sounddevice = "^0.4.6"
soundfile = "^0.12.1"
pyperclip = "^1.8.2"
pyautogui = "^0.9.54"
numpy = "^2.0.0"

# Windows Service Components
pynput = "^1.7.6"
pystray = "^0.19.5"
pillow = "^10.0.0"
pyyaml = "^6.0.1"

# Note: faster-whisper uses CTranslate2 (automatically included)
# No need for PyTorch! Works with RTX 5080 out of the box
# Pin CTranslate2 to 4.6.1 - version 4.6.2 has a crash bug with large-v3 model
ctranslate2 = "4.6.1"
kokoro-onnx = {extras = ["gpu"], version = "^0.4.9"}

# LLM integration
aiohttp = "^3.9.0"  # For Ollama API calls
requests = "^2.31.0"  # For synchronous API calls in tray
psutil = "^5.9.8"

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
black = "^23.7.0"
ruff = "^0.0.285"
pyinstaller = "^6.0.0"
winshell = "^0.6"
pywin32 = "^311"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dictator = "dictator.main:main"
dictator-service = "dictator.service:main"
dictator-tray = "dictator.tray:main"
