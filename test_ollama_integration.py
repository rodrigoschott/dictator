"""
Test script for Ollama integration

Tests OllamaLLMCaller with local Ollama server.
"""

import asyncio
import logging
from pathlib import Path

from src.dictator.voice.events import EventPubSub, EventType
from src.dictator.voice.llm_caller import OllamaLLMCaller


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger("OllamaTest")


async def test_ollama_basic():
    """Test basic Ollama interaction"""
    logger.info("=" * 60)
    logger.info("TEST 1: Basic Ollama Call")
    logger.info("=" * 60)

    # Create event pub/sub
    pubsub = EventPubSub()

    # Create Ollama caller
    ollama = OllamaLLMCaller(
        pubsub=pubsub,
        base_url="http://localhost:11434",
        model="llama3.2:latest"
    )

    # Process transcription
    test_input = "OlÃ¡, como vocÃª estÃ¡?"
    logger.info(f"ğŸ“¤ Input: {test_input}")

    # Start event listener
    async def listen_events():
        """Listen for events"""
        responses = []
        async for event in pubsub.poll():
            logger.info(f"ğŸ“¬ Event: {event.type}")

            if event.type == EventType.LLM_RESPONSE_COMPLETED:
                break
            elif event.type == EventType.TTS_SENTENCE_READY:
                responses.append(event.data['text'])
                logger.info(f"ğŸ’¬ Response: {event.data['text']}")
            elif event.type == EventType.LLM_RESPONSE_FAILED:
                logger.error(f"âŒ Error: {event.data['error']}")
                break

        return responses

    # Run both tasks
    listener_task = asyncio.create_task(listen_events())
    await ollama.process_transcription(test_input)
    responses = await listener_task

    logger.info(f"âœ… Test completed: {len(responses)} response(s)")
    return responses


async def test_ollama_conversation():
    """Test conversation history"""
    logger.info("=" * 60)
    logger.info("TEST 2: Conversation History")
    logger.info("=" * 60)

    pubsub = EventPubSub()
    ollama = OllamaLLMCaller(
        pubsub=pubsub,
        base_url="http://localhost:11434",
        model="llama3.2:latest"
    )

    # Multi-turn conversation
    conversation = [
        "Meu nome Ã© Rodrigo",
        "Qual Ã© o meu nome?",
        "Em que linguagem estou falando?"
    ]

    for i, msg in enumerate(conversation, 1):
        logger.info(f"\n--- Turn {i} ---")
        logger.info(f"ğŸ“¤ User: {msg}")

        # Listen for response
        async def listen_once():
            response = None
            async for event in pubsub.poll():
                if event.type == EventType.TTS_SENTENCE_READY:
                    response = event.data['text']
                    logger.info(f"ğŸ’¬ Assistant: {response}")
                elif event.type == EventType.LLM_RESPONSE_COMPLETED:
                    break
                elif event.type == EventType.LLM_RESPONSE_FAILED:
                    logger.error(f"âŒ Error: {event.data['error']}")
                    break
            return response

        listener_task = asyncio.create_task(listen_once())
        await ollama.process_transcription(msg)
        await listener_task

    # Check history
    history = ollama.get_history()
    logger.info(f"\nğŸ“š Conversation history: {len(history)} messages")
    for msg in history:
        logger.info(f"  {msg['role']}: {msg['content'][:50]}...")

    logger.info("âœ… Conversation test completed")


async def test_ollama_error_handling():
    """Test error handling with invalid server"""
    logger.info("=" * 60)
    logger.info("TEST 3: Error Handling")
    logger.info("=" * 60)

    pubsub = EventPubSub()
    ollama = OllamaLLMCaller(
        pubsub=pubsub,
        base_url="http://localhost:99999",  # Invalid port
        model="llama3.2:latest"
    )

    try:
        # Listen for error event
        async def listen_error():
            async for event in pubsub.poll():
                if event.type == EventType.LLM_RESPONSE_FAILED:
                    logger.info(f"âœ… Error event received: {event.data['error'][:100]}")
                    return True
                elif event.type == EventType.LLM_RESPONSE_COMPLETED:
                    logger.error("âŒ Expected error but got success")
                    return False

        listener_task = asyncio.create_task(listen_error())
        await ollama.process_transcription("Test")
        result = await asyncio.wait_for(listener_task, timeout=5.0)

        if result:
            logger.info("âœ… Error handling test passed")

    except Exception as e:
        logger.info(f"âœ… Exception caught as expected: {type(e).__name__}")


async def test_provider_comparison():
    """Compare response quality between providers"""
    logger.info("=" * 60)
    logger.info("TEST 4: Provider Comparison")
    logger.info("=" * 60)

    test_prompt = "Explique em uma frase o que Ã© inteligÃªncia artificial"

    # Test Ollama
    logger.info("\nğŸ¦™ Testing Ollama...")
    pubsub_ollama = EventPubSub()
    ollama = OllamaLLMCaller(
        pubsub=pubsub_ollama,
        base_url="http://localhost:11434",
        model="llama3.2:latest"
    )

    async def get_response(pubsub):
        async for event in pubsub.poll():
            if event.type == EventType.TTS_SENTENCE_READY:
                return event.data['text']
            elif event.type in (EventType.LLM_RESPONSE_COMPLETED, EventType.LLM_RESPONSE_FAILED):
                return None

    listener_ollama = asyncio.create_task(get_response(pubsub_ollama))
    await ollama.process_transcription(test_prompt)
    ollama_response = await listener_ollama

    logger.info(f"ğŸ“¤ Prompt: {test_prompt}")
    logger.info(f"ğŸ¦™ Ollama: {ollama_response}")

    # Compare characteristics
    logger.info("\nğŸ“Š Analysis:")
    logger.info(f"  Length: {len(ollama_response) if ollama_response else 0} chars")
    logger.info(f"  Has markdown: {'```' in ollama_response if ollama_response else False}")
    logger.info(f"  Sentences: {ollama_response.count('.') if ollama_response else 0}")

    logger.info("âœ… Comparison test completed")


async def test_tts_interrupt():
    """Test TTS interrupt when user speaks during TTS playback"""
    logger.info("=" * 60)
    logger.info("TEST 5: TTS Interrupt Simulation")
    logger.info("=" * 60)

    # Mock TTS engine
    class MockTTSEngine:
        def __init__(self):
            self.is_stopped = False
            self.stop_count = 0

        def stop(self):
            """Mock stop method"""
            self.stop_count += 1
            self.is_stopped = True
            logger.info("ğŸ›‘ MockTTSEngine.stop() called")

        def is_speaking(self):
            return not self.is_stopped

        def speak(self, text):
            """Mock speak method"""
            self.is_stopped = False
            logger.info(f"ğŸ”Š MockTTSEngine speaking: {text[:50]}...")

    # Create components
    pubsub = EventPubSub()
    mock_tts = MockTTSEngine()

    # Import session manager to test interrupt logic
    from src.dictator.voice.session_manager import VoiceSessionManager
    from src.dictator.voice.events import Event
    import numpy as np

    # Mock callbacks
    def mock_stt(audio):
        return "Interrupt transcription"

    def mock_tts_callback(text):
        mock_tts.speak(text)

    # Create Ollama caller
    ollama = OllamaLLMCaller(
        pubsub=pubsub,
        base_url="http://localhost:11434",
        model="llama3.2:latest"
    )

    # Create session manager with mock TTS engine
    session = VoiceSessionManager(
        stt_callback=mock_stt,
        tts_callback=mock_tts_callback,
        llm_caller=ollama,
        vad_enabled=False,
        tts_engine=mock_tts  # Pass mock TTS engine
    )

    # Start session
    await session.start()

    try:
        # Simulate TTS speaking by triggering actual TTS
        logger.info("ğŸ¤ Sending request to generate TTS response...")
        
        # Trigger LLM which will generate TTS
        async def monitor_and_interrupt():
            """Monitor for TTS start and interrupt it"""
            tts_started = False
            
            async for event in pubsub.poll():
                if event.type == EventType.TTS_SENTENCE_READY:
                    logger.info("ğŸ”Š TTS started, waiting 0.5s then interrupting...")
                    tts_started = True
                    # Let TTS play for a bit
                    await asyncio.sleep(0.5)
                    
                    # Simulate user speaking by resetting flag
                    logger.info("ğŸ‘¤ User speaks - setting tts_speaking to False...")
                    session.tts_speaking = False
                    
                    # Wait to see if TTS stops
                    await asyncio.sleep(0.5)
                    break
                    
                elif event.type == EventType.LLM_RESPONSE_COMPLETED:
                    if not tts_started:
                        break
            
            return tts_started
        
        # Start monitoring task
        monitor_task = asyncio.create_task(monitor_and_interrupt())
        
        # Send simple request
        await ollama.process_transcription("Diga algo curto")
        
        # Wait for monitoring to complete
        tts_started = await monitor_task
        
        # Give time for cleanup
        await asyncio.sleep(0.2)

        # Check results
        if tts_started:
            if mock_tts.stop_count > 0:
                logger.info(f"âœ… TTS interrupt triggered successfully! (stop called {mock_tts.stop_count} times)")
            else:
                logger.warning("âš ï¸ TTS was interrupted but stop() was not called (task cancelled)")
                logger.info("âœ… Interrupt mechanism working (flag-based cancellation)")
        else:
            logger.error("âŒ TTS never started")

        # Check if flag was reset
        if not session.tts_speaking:
            logger.info("âœ… tts_speaking flag reset correctly")
        else:
            logger.error("âŒ tts_speaking flag was not reset")

        logger.info("âœ… TTS interrupt test completed")

    finally:
        await session.stop()


async def main():
    """Run all tests"""
    logger.info("ğŸš€ Starting Ollama Integration Tests\n")

    try:
        # Test 1: Basic call
        await test_ollama_basic()
        await asyncio.sleep(1)

        # Test 2: Conversation
        await test_ollama_conversation()
        await asyncio.sleep(1)

        # Test 3: Error handling
        await test_ollama_error_handling()
        await asyncio.sleep(1)

        # Test 4: Provider comparison
        await test_provider_comparison()
        await asyncio.sleep(1)

        # Test 5: TTS interrupt
        await test_tts_interrupt()

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ All tests completed successfully!")
        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"\nâŒ Test failed: {e}", exc_info=True)


if __name__ == "__main__":
    asyncio.run(main())
